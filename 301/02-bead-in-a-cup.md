# ğŸ§­ A Bead in a Cup

Weâ€™re not zooming out right now. Weâ€™re zooming in. All the way down to a single cup in the system.

The bead â€” our unit of work â€” just dropped in.
Now itâ€™s time to move it forward.

Thatâ€™s what context engineering is really about: giving the AI what it needs â€” not to do *everything*, but to do *this next thing*. One step. One contribution. One cup to the next.

Letâ€™s take a concrete case.

## ğŸ¯ Use Case: Build the Final Daily Itinerary

Weâ€™re in the middle of planning a trip to Japan. The big decisions are made, key bookings are secured, and the family has already picked out the experiences theyâ€™re most excited about.

Our goal now is to build a clear, human-friendly itinerary â€” one that reflects those commitments, organizes the days sensibly, and includes suggestions for additional activities where time allows.

### Inputs

* ğŸ“„ **Confirmed Bookings Summary** â€” All the purchased tickets and reservations: flights, hotels, and a handful of timed activities.
* ğŸ“„ **Experience Bucket List** â€” A set of interesting activities the family picked earlier in the planning process.
* ğŸ¤– **Activity Formatting Rules** â€” A simple process artifact describing how each day should be written up (clarity, structure, helpful travel cues).

### Output

* ğŸ“„ **Final Daily Itinerary** â€” A sequenced, structured plan for each day, with confirmed events and optional add-ons.

## ğŸ” The Inputs, Up Close

### ğŸ“„ Confirmed Bookings Summary

This document captures all locked-in reservations. For this trip, that includes:

* Hotels in Kyoto, Kiso Valley, and Osaka
* Planned excursions for:

  * **Kiyomizu-dera Temple** (Kyoto)
  * **Nakasendo Trail Hike** (Kiso Valley)
  * **Universal Studios** (Osaka)

These werenâ€™t casual adds â€” they were considered the â€œrocksâ€ of the trip. High-value experiences that shaped the travel path and defined the itinerary backbone. Youâ€™ll find them listed both in the Experience Bucket List *and* in this booking summary. That overlap matters.

### ğŸ“„ Experience Bucket List

This came from an earlier phase, where the family explored potential activities near each hotel. Everyone got a say. The list they built includes attractions, food experiences, cultural sites â€” anything that sparked interest.

Each item comes with **GPS coordinates**.

Now, humans donâ€™t think in lat/long. But machines do. And that matters more than you might think.

By capturing coordinates, you give the AI the spatial information it needs to reason through the geography â€” grouping nearby activities, identifying natural day plans, and using the hotel locations as hubs for exploring the area. It's how the model learns whatâ€™s close enough to combine.

This isnâ€™t decoration. Itâ€™s what makes routing, clustering, and prioritizing feasible.

#### ğŸ¤– Aside: Designing for AX

UX is for humans. AX is for AI.

When you enrich your documents with structured, machine-readable cues â€” GPS coordinates, clean dates, standardized names â€” youâ€™re improving not the *feel*, but the *function* of the document from an AIâ€™s perspective.

Itâ€™s not about writing in JSON. Youâ€™re still writing for people.

But youâ€™re also **writing with machines in mind**.

Thatâ€™s the shift. Weâ€™re not the only reader anymore.

Adding small details like coordinates, booking references, or even travel time estimates isnâ€™t overhead. Itâ€™s part of **context engineering** â€” crafting inputs that a machine can actually use to reason through the next step.

The result? Better output, less back-and-forth, and a process that starts to feel like a system.

### ğŸ¤– Activity Formatting Rules

This lightweight guide set the tone for how each day should be written. It covered things like:
*Structure the day chronologically. Use bold headers for key events. Clearly separate fixed bookings from optional add-ons.*

But it wasnâ€™t just about structure â€” it also carried **human priorities**.

For example, this particular family had accessibility needs. So the formatting rules included a short instruction:
*â€œFlag each activity with accessibility notes when relevant â€” stairs, ramps, terrain, etc.â€*

That one line shaped the entire output. It ensured the itinerary spoke directly to the family's real-world constraints, without needing to be re-edited afterward.

This is what makes the formatting guide special. Itâ€™s a **process artifact**, yes â€” but also a **human artifact**. It allowed the user to **imprint their priorities** into the process and get results that actually fit their life.

Had that instruction not been captured in the document, the model wouldnâ€™t have known. The output wouldâ€™ve been â€œfineâ€ â€” but not *for them*.

## âš™ï¸ The Moment of Traction

Letâ€™s zoom in on the moment the bead moved.

This wasnâ€™t a vibe check. It wasnâ€™t magic. It was a **command** â€” supported by real data.

The prompt that drove things forward:

> â€œUse these three documents â€” the Confirmed Bookings Summary, the Experience Bucket List, and the Activity Formatting Rules â€” to generate a final daily itinerary for the Japan trip, formatted as requested.â€

Thatâ€™s the bead moving from one cup to the next.

A single, explicit ask.

With all the materials needed to fulfill it.

Letâ€™s break it down:

1. ğŸ“„ **Confirmed Bookings Summary** â€” a **product artifact** listing whatâ€™s locked in.
2. ğŸ“„ **Experience Bucket List** â€” a **product artifact** listing whatâ€™s desired.
3. ğŸ¤– **Activity Formatting Rules** â€” a **process artifact** describing how the result should be shaped.

Together, these formed the full context. Not in the modelâ€™s memory. Not implied in conversation.

**Visible. Present. Supplied.**

The result? A clear, structured daily itinerary.

Confirmed events anchored the days. Optional activities clustered by proximity. Accessibility needs respected. Formatting consistent.

None of that was guessed. It was derived â€” from the prompt and the payload.

From data in the cup.

Thatâ€™s the bead-in-a-cup metaphor, made real, the epitome of **atomicity**.

Incidentally, this is also what a **function** in a computer program looks like in practice:

* The prompt is the function signature.
* The artifacts are the parameters.
* The output is (or can be) deterministic, shaped by inputs alone.

This is **context engineering** at its core.

Youâ€™re not â€œasking ChatGPT to help.â€

Youâ€™re designing a system moment â€” a reproducible unit of AI labor, shaped by structure and scope.

Youâ€™re building a world the model can see â€” then asking it to take the next step.

Thatâ€™s how you move the bead.

Thatâ€™s the real work.

And now youâ€™ve seen it land.

## ğŸ§± The Artifacts Are the Infrastructure

This prompt didnâ€™t work in a vacuum. It worked because earlier steps produced **artifacts**.

* A checklist of experiences
* A structured booking summary
* A shared format for writing things down

These arenâ€™t fancy. Theyâ€™re markdown files, tables, bullet lists â€” whatever captured the state of the work.

But thatâ€™s the point.

They made the prompt possible.

They *enabled* the AI to perform real labor.

Thatâ€™s what most people miss.

They want the chatbot to â€œplan their tripâ€ â€” but without the scaffolding, the model is guessing in the dark. The groundwork has to be there.

And once it is? Youâ€™re not asking it to plan the whole trip.

Youâ€™re asking it to move the bead.

And this is what LLMs make possible â€” not because theyâ€™re guessing, but because they can now act on a command *if* the right information is already in view. Thatâ€™s the real shift:

AIs can write deliverables. They can recommend actions. They can reason through a situation. But only when the inputs are there â€” right there, piped into the cup at the moment of execution.

The bottleneck isnâ€™t the model. Itâ€™s us.

We havenâ€™t built the infrastructure to carry forward the artifacts, decisions, and constraints that make a command actionable. The model is ready to do the work. Our job is to support that moment â€” to structure what matters, and deliver it when it counts.

Thatâ€™s the new frontier of systems design.

## Meeting the Fork

Back in the *Reifying Process* chapter, we talked about the spectrum.

* **Lean left** and you steer the conversation, one volley at a time
* **Lean right** and the system carries the memory, the baton, the state

In this case, we leaned right â€” we passed in artifacts, gave it everything at once.

That only works if *everything at once* already exists.

And that means prior work.

The bookings were already made. The preferences were already collected. The formatting rules were already agreed on.

What made the prompt work wasnâ€™t just the instruction. It was the infrastructure:
**Artifacts** that captured what mattered, in a way the model could act on.

We couldâ€™ve leaned left. You could have had a long chat, describing your hotels, your must-do activities, your preferences. As long as those ideas were exposed â€” in conversation, not just in your head â€” the model couldâ€™ve done the same thing.

Thatâ€™s what â€œcontextâ€ means. It doesnâ€™t matter whether it lives in a file or in a transcript. It just needs to exist â€” and be accessible when itâ€™s needed.

## ğŸ§  The New Piece

Everything weâ€™ve seen so far â€” the way the bead moves, the way the model performs â€” rests on one thing: giving it the right inputs at the right time.

Thatâ€™s not new. Systems have always worked this way.

Long before LLMs, developers were already building the infrastructure for continuity.

*Databases held decisions.*

*APIs triggered actions.*

*Formats and schemas carried priorities forward.*

Memory wasnâ€™t a metaphor. It was a backend.

The tools? Not novel either. Weâ€™ve had them for decades â€” browsers, schedulers, scripts, triggers, queues. Systems got things done because we told them what mattered and when.

Whatâ€™s new isnâ€™t that structure.

Itâ€™s that now, at the moment of execution, a brain can join the loop.

Thatâ€™s the shift.

The memoryâ€™s always been there.

The tools have been ready.

Now the brain shows up â€” and asks how it can help.

But itâ€™s a brain in a jar.

It canâ€™t act. It canâ€™t feel its way forward.

It can only see what you show it.

If the data arrives with the bead â€” if the pipeline delivers what it needs, just like it always has â€” then the brain can contribute. Not by guessing, but by reasoning.

And what it reasons from is the payload.

Every artifact, decision, and constraint required to take the next step â€” already in the cup.

Thatâ€™s what makes the bead move.

Thatâ€™s the handoff.

## ğŸ§  Thatâ€™s Context Engineering

Itâ€™s not magic. Itâ€™s not command-only.

Itâ€™s **prompt + artifacts** â€” the instruction *and* the materials.

Itâ€™s recognizing that AI canâ€™t pull from your mind â€” it can only work with whatâ€™s in view.

**Context engineering is putting enough integrity into what's been captured and communicated in your prompt and payload that one can reasonably anticipate a good output.**

The more visible your process becomes, the better you get at exposing the necessary information, the more likely your AI will be able to assist.

Thatâ€™s the handoff.

Thatâ€™s how you move the bead.

## ğŸ‘€ Whatâ€™s Next

We all know what itâ€™s like to lean left. To bring in AI when weâ€™re stuck, or when a task feels small and self-contained. We paste in a bit of context, talk through the shape of what we want, maybe try a few rewrites. The help is real â€” but so is the overhead.

Because unless weâ€™ve already laid the groundwork, even a smart assist becomes a manual job. We spend time gathering references, restating what we know, walking the model through constraints weâ€™re holding in our heads. It can feel more like narrating than collaborating.

So we donâ€™t do it often. We stick to using AI for isolated tasks â€” things we can hand off in one shot. And we avoid inviting it into the bigger work. Not because the model canâ€™t help, but because the logistics are brutal. The friction is too high. Itâ€™s easier to do it ourselves.

**Thatâ€™s why we want to shift things to the right.**

To do that, to make the whole projects tractable, you need to build scaffolding to carry memory, structure, and priorities forward â€” not just to make the next prompt easier.  The goal is to **build systems where thinking happens inside the loop**.

Youâ€™ve seen what happens when a brain joins the process â€” when it has the right inputs, at the right time, and can reason from them.

Now imagine that brain sitting *next to the bead*.

Not off to the side, waiting for you to intervene. Not in a chatbot thread you have to copy everything into.

**Right there in the cup.**

Thatâ€™s whatâ€™s starting to happen.

Tools are emerging that donâ€™t just carry the data â€” they carry the *intelligence*. Agents that can spot what's missing, fill in gaps, reformat, restructure, even route artifacts downstream.

The bead doesnâ€™t just move because you told it to.

It moves because you engineered a system that knows what to do with it.

The next frontier isnâ€™t just asking AI to assist â€” itâ€™s designing environments where its contribution is built in.

Where moving the bead doesnâ€™t require a prompt, because the system already knows what matters.


## âœˆï¸ Modeling a Harder Problem: Picking the Best Flight

Letâ€™s move the bead again. But this time, letâ€™s pick a messier moment â€” one that forces more context into view.

In course of planning an international trip, what'd be helpful is having the AI find us a flight.

What would it take to get a chatbot to make a smart recommendation â€” or at least shortlist three options that meet your needs?

You canâ€™t just say, *â€œWhich one should I pick?â€* and expect brilliance. Thatâ€™s not context engineering. Thatâ€™s a shrug in the dark.

You need to think like a system designer.

So step back. Imagine you were doing this yourself. Or better yet, imagine you were handing it off to a smart assistant â€” one with no prior knowledge of your preferences or the options available.

What would you give them?

Two things:

1. A list of flight options (the candidates).
2. A clear traveler profile (your decision criteria).

Thatâ€™s the anatomy of the moment. Two inputs. One ask. And if youâ€™ve framed them well, the AI can do useful work.

Letâ€™s walk through what each artifact needs to look like.

### ğŸ“„ Traveler Profile (Process Artifact)

This is the cheat sheet â€” a way to help the AI see how *you* think about flights.

You donâ€™t need a special format. A simple markdown file works fine. Use plain language. Use bullets. Weight your preferences if that helps.

For example:

```markdown
# Traveler Profile

## Preferences (in rough order of importance)

- Cost matters. Avoid outliers â€” we donâ€™t always pick the cheapest, but extreme prices are disqualifying.
- Prefer nonstop flights. Willing to accept one connection if it significantly improves cost or schedule.
- Avoid long layovers (more than 3 hours) and too-short layovers (less than 45 minutes).
- Departure/arrival time should align with normal waking hours (no red-eyes unless necessary).
- Favor known carriers over budget airlines, unless cost savings are substantial.
```

This isnâ€™t about being exhaustive. Itâ€™s about being clear enough that someone else â€” human or AI â€” can juggle your tradeoffs.

Thatâ€™s why itâ€™s a **process artifact**. It doesnâ€™t depend on where youâ€™re going. It applies across trips.

### ğŸ“„ Flight Search Results (Product Artifact)

This is the raw material. The actual flight options on the table.

Now, in a real system, youâ€™d query an API. But most flight sites donâ€™t make their data exportable. So what do you do?

You make a reasonable facsimile.

You ask the AI to play C-3PO.

Hereâ€™s the move:

> â€œPretend Iâ€™m searching for roundtrip flights from BWI to Kyoto (with outliers like IAD or JFK allowed). Use the Skyscanner API format as a guide. I need realistic mock data â€” at least 200 itineraries, in JSON. Include carrier, price, layover details, total travel time, etc.â€

Thatâ€™s it. Youâ€™re not looking for real data â€” youâ€™re modeling the shape of it. Because the shape is enough to practice the moment.

You donâ€™t need the actual trip. You need the structure.

Once youâ€™ve got that mock data, youâ€™re ready to move the bead.

### ğŸ§  The Moment of Execution

The setup is done. Now comes the ask:

> â€œGiven our traveler profile (attached) and this list of flight options (attached), recommend the best flight. List two alternates for comparison.â€

The AI doesnâ€™t need memory. It doesnâ€™t need backstory. It just needs these two artifacts â€” dropped cleanly in the cup.

Thatâ€™s when you watch it work.

Youâ€™re not expecting perfection. Youâ€™re testing for traction.

Did it pick flights that align with your priorities? Did it weigh tradeoffs in the way you hoped?

Maybe. Maybe not.

And if not â€” now you iterate. You revise your traveler profile. You tweak how you framed the tradeoffs. You run it again. Thatâ€™s how you mentor the AI.

Youâ€™re not grading a student. Youâ€™re training a teammate.

### ğŸ›  From Modeling to System Design

This is what â€œmoving the beadâ€ really means. Not just issuing a prompt, but engineering the moment so a smart tool can act meaningfully.

And if you can do it in ChatGPT, you can do it anywhere.

Picture the same logic embedded in a Power Automate flow â€” traveler profile and flight results piped in as variables. The LLM evaluates and outputs a shortlist. Now that same bead moves in Microsoft land.

Or maybe it lives in a browser extension. Or a console app. Or a shared team tool.

The form doesnâ€™t matter. The inputs do.

Because once you know what the moment *requires*, building the environment is just infrastructure work.

### ğŸ§­ Why This Matters

This whole exercise wasnâ€™t about flights. It was about **context engineering**.

You built a prompt, yes â€” but more importantly, you built the **payload**. You isolated the exact inputs that shape a good decision, and you wrapped them in a frame the AI could act on.

Thatâ€™s the skill. Thatâ€™s the shift.

And thatâ€™s how system design starts: not with automation, but with a moment.

You moved the bead.
