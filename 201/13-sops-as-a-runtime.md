# SOPs as a Runtime

## Design the Process, Not Just the Parts

**Show me your process, and Iâ€™ll show you your results.**

AI doesnâ€™t just let you divide work into tasks. It lets you **design processes** that wouldâ€™ve been too costly or complicated before. Thatâ€™s a shift every teamâ€”large or smallâ€”should be thinking about.

As W. Edwards Deming put it, *â€œIf you canâ€™t describe what you are doing as a process, you donâ€™t know what youâ€™re doing.â€*

> *â€œA bad system will beat a good person every time.â€* â€” Deming

That applies to AI too. If the system isnâ€™t soundâ€”if the specs are vague, or the stages arenâ€™t definedâ€”youâ€™ll get unpredictable results, no matter how capable the AI is. What changes everything is **deliberate process design**, using AI as a teammate at each stage.

Which brings us back to something we've touched throughout: stages and waypoints.

Each stage in a process defines a place where meaningful byproducts should emergeâ€”intermediate outputs that shape the final result. These arenâ€™t throwaway drafts. Theyâ€™re signals. Snapshots of your thinking. Opportunities to inspect, intervene, or redirect before things veer off course.

A waypoint might be a messy outline, a tone guide, a first-pass summary, or a critique of structure. What matters is that you *materialize the thought*â€”you make it visible. And once itâ€™s visible, you can act on it.

Waypoints are checkpoints for quality and alignment. Each one is a chance to:

* Shape outcomes intentionally
* Halt missteps before they become entrenched
* Capture your standards as reusable artifacts

This is the hidden value of process: not just throughput, but **thought visibility**. Each stage creates space for waypoints, and each waypoint gives you leverage.

Thatâ€™s how structured collaboration worksâ€”not by skipping ahead, but by knowing where to pause, inspect, and shape.

---

## SOPs Are Not for Bots â€” Theyâ€™re for Workers

Itâ€™s tempting to rewrite everything around AI. To build special procedures for â€œvirtual teammates.â€ To treat chatbots like a new species of employee that demands custom processes.

But thatâ€™s backwards.

> **SOPs should be worker-agnostic.**
> Whether the actor is human or virtual shouldnâ€™t matterâ€”what matters is that they can understand the step and perform it to standard.

A good SOP describes the *what* and the *why*. It outlines what quality looks like. But it doesnâ€™t prescribe *who* performs it. And it definitely doesnâ€™t wrap itself around the quirks of a specific tool.

Thatâ€™s not to say AI is invisible. Some steps benefit greatly from virtual teammatesâ€”ones who can synthesize, transform, or iterate rapidly. But the point is this:

> **When you learn how to pilot AI well, you stop needing AI-specific processes.**
> You start seeing work as modular. You delegate by skill, not species.

And when you understand how to delegate to AI, you can **slot it seamlessly into your process**â€”without having to rewrite that process around it.

---

## ðŸ§­ Running the SOP Manually â€” With a Virtual at the Table

Letâ€™s make this real.

You have a process file called:

> `SOP: Drafting Internal Product Docs`
> (stored at `/Documents/SOPs/drafting-product-docs.md`)

This is your standard operating procedure for creating IT-facing documentationâ€”system overviews, onboarding guides, feature explainers. Itâ€™s used by human teammates across multiple departments.

Hereâ€™s what it includes:

1. Identify the target audience and their common questions
2. Build a topic outline focused on user workflows
3. Draft section content in plain, direct language
4. Apply tone/style guide and format for readability
5. Spot-check accuracy using examples or config snippets

Now, for your latest docâ€”an internal guide to the identity platformâ€”you decide to enlist help from ChatGPT.

Not because the SOP says to.
But because **you know how to pilot a chatbot well.**

---

### ðŸ“¥ Step 1: Delegating Intelligently

You begin the session by pasting in the SOP:

> **Prompt:**
> *Hereâ€™s our SOP for drafting product docs. Youâ€™re to follow it with me as I build documentation for our identity platform. Wait for my cue before each step. Let me know once youâ€™ve read it.*
>
> \[uploads SOP]

ChatGPT replies:

> Understood. The SOP has 5 steps. Ready when you are.

You reply:

> Start with Step 1. The audience is new IT hires onboarding this quarter.

---

### ðŸ› ï¸ Step 1 Output: Identify the Target Audience

> **Audience Summary:**
> â€“ First 90 days on the job
> â€“ Working through onboarding modules
> â€“ High urgency for role-based access clarity
>
> **Common Questions:**
> â€“ What does this platform manage?
> â€“ Why do I have access to things I didnâ€™t request?
> â€“ How do I change my access?
> â€“ Whatâ€™s expected of me re: MFA, password changes, etc.?

You review the output and realize somethingâ€™s missing.

You respond:

> Add: â€œWhat happens if I leave a team or project?â€ Thatâ€™s often overlooked.

ChatGPT updates the list.

âœ… Step 1 completeâ€”*and better than it wouldâ€™ve been alone.*

You move on:

> Letâ€™s do Step 2.

---

### ðŸ› ï¸ Step 2 Output: Topic Outline

> 1. What the Platform Manages
> 2. Who Gets Access and Why
> 3. Role Inheritance and Surprise Access
> 4. Requesting or Changing Access
> 5. Leaving a Team: What Happens
> 6. MFA and Password Management
> 7. Audit Trails and Access History

You notice how that last insightâ€”*Leaving a Team*â€”has now shaped the structure itself. Thatâ€™s what good process enables: judgment captured and turned into structure.

You decide itâ€™s time to update the process.

---

### ðŸ” Updating the SOP Itself

You prompt:

> Insert this line into Step 1:
>
> > â€œPrompt for common confusions around lifecycle events (e.g. team transfers, departures) that affect access.â€

ChatGPT returns the updated markdown. You save it to:

> `/Documents/SOPs/drafting-product-docs.md`

No forked process. No separate â€œAI workflow.â€
Just a smarter SOPâ€”ready for any teammate to follow.

---

## Spec Your Team, Not Just Your Task

Thatâ€™s the shift. Youâ€™re no longer just specifying a task. Youâ€™re **specifying a team**.

Each stage of work can be broken out, defined, and refined independently. You can even review their performance in isolation: â€œHow is my structural editor bot doing? Are they skipping steps?â€ If so, update *that* part of the playbook.

You are building a well-oiled machine. And every part of it runs on the specs you provide.

---

## Clones Can Review Each Other

And it gets even better: your clones can *critique* each other.

People often talk about AIâ€™s weaknessesâ€”hallucinations, misfires, overconfidence. And those are real. But hereâ€™s the twist: people have those weaknesses too. Thatâ€™s why process exists. It creates **stages**. It defines **roles**. It introduces **checks**. The whole point of a well-structured SOP is to embed those controls into the flow of work.

Whatâ€™s remarkable is that AI doesnâ€™t just participate in that structureâ€”it *thrives* in it.

The same AI that makes a mistake in one role can be told to put on a different hatâ€”to check facts, to question assumptions, to search for supportâ€”and it does. Not because it â€œfeels bad,â€ but because itâ€™s following the system you designed.

> Itâ€™s kind of funny, honestly. The same knucklehead that hallucinated the problem is now the one catching itâ€”because the process told them to.

Imagine this:

* One clone drafts a summary.
* A second clone fact-checks it against policy or source material.
* A third applies tone and formatting rules.

Thatâ€™s not magic. Thatâ€™s *structured reuse of intelligence*. Each clone running a different version of your spec, performing a role in your system.

And if one messes up? The system catches itâ€”because your waypoints are designed to make the invisible visible.

Even better? You can have the model critique *itself* from another angle. With just a prompt, it can switch modes:

> "Now review that summary for unsupported claims. Highlight anything that might require citation."

It can even run a web search to confirm factsâ€”if you ask it to.

The point is, process enables that. Not faith in the model, but confidence in the **system** youâ€™ve built around it.

---

## SOPs Are Code

I donâ€™t want you to miss whatâ€™s happening here:

> **SOPs are now programs.**

They are the operational logic we used to hand to people.
Now we hand them to machines.

And the results are shockingly reliableâ€”if the spec is good.

Youâ€™re no longer just writing instructions to align humans.
Youâ€™re writing instructions that *get executed*.

Let that sink in:
**Your SOPs now have runtime.**

---

## The Architecture That Makes It Work

Letâ€™s ground this in the architecture youâ€™ve seen throughout this book:

* **Brain**: The LLM, the engine that runs your specs
* **Memory**: The payload, the instructions, and context you provide
* **Tools**: Optional extensions that let your clone reach into files, systems, or other workflows

Almost every AI tool todayâ€”including ChatGPTâ€”bundles these parts for you. But ChatGPT is just one app. Increasingly, other systems are bundling them too: LLMs, memory, tools. These junctions are appearing everywhereâ€”in CRMs, ticketing platforms, IDEs, and project tools. Yet weâ€™re still in the infancy of figuring out what to actually do with them.

The LLM is the heart of that opportunity. The brain. The decision engine. The partner. And the more intimate your understanding of what LLMs are good atâ€”where they help, where they misfireâ€”the more clearly youâ€™ll see where they can be slotted into meaningful work.

---

## Practicing at Scale: Your Proving Ground

This is where it all comes togetherâ€”stages, waypoints, artifacts, and specs.

So how do you actually get there?

Not through theory. Through practice.

Consider a project in your world that:

* Involves multiple stages or steps
* Produces many artifacts
* Would benefit from repeatability
* Is something youâ€™ll likely do again and again

Thatâ€™s your proving ground.

Apply everything weâ€™ve modeled so far:

* Use intermediate artifacts as checkpoints
* Define waypoints that reflect key insights or deliverables
* Shape the workflow using labeled specs and examples

ChatGPT is the perfect environment for this kind of structured trial. Upload your waypointsâ€”tone guides, feedback snippets, structure examples. Create prompts that reference them clearly. Then watch the AI work from those specs to generate output.

Youâ€™ll see just how much those materials influence the outcome. And when something goes wrong? You donâ€™t just tweak the output. You improve the *payload*â€”those modular inputs that shape every future run.

This kind of practice is more than just producing a good deliverable. Itâ€™s preparing you to work with LLMs fluently. When you see how to shape the input, what kind of artifacts create leverage, and where the junction points are in your workflows, youâ€™re gaining something deeper than technique.

Youâ€™re gaining insight.
And thatâ€™s what prepares you to operate at the next level.

---

## Final Shift: From Suit to Staff

You started this journey thinking of AI as a suit of armor. Now, you should see it as something else entirely:
**A staff of eager new hires, ready to follow your lead.**

The tools are powerful. The memory is real. The brain is sharp.

But what changes everything is this:

> **Youâ€™ve created a workforce that works like you do.**
> And you did it not by rewriting the SOP, but by learning how to staff it well.
