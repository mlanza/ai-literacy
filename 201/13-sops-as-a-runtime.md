# SOPs as a Runtime

## Design the Process, Not Just the Parts

**Show me your process, and Iâ€™ll show you your results.**

AI doesnâ€™t just let you divide work into tasks. It lets you **design processes** that wouldâ€™ve been too costly or complicated before. Thatâ€™s a shift every teamâ€”large or smallâ€”should be thinking about.

As W. Edwards Deming put it, *â€œIf you canâ€™t describe what you are doing as a process, you donâ€™t know what youâ€™re doing.â€*

> *â€œA bad system will beat a good person every time.â€* â€” Deming

That applies to AI too. If the system isnâ€™t soundâ€”if the specs are vague, or the stages arenâ€™t definedâ€”youâ€™ll get unpredictable results, no matter how capable the AI is. What changes everything is **deliberate process design**, using AI as a teammate at each stage.

Which brings us back to something we've touched throughout: stages and waypoints.

Each stage in a process defines a place where meaningful byproducts should emergeâ€”intermediate outputs that shape the final result. These arenâ€™t throwaway drafts. Theyâ€™re signals. Snapshots of your thinking. Opportunities to inspect, intervene, or redirect before things veer off course.

A waypoint might be a messy outline, a tone guide, a first-pass summary, or a critique of structure. What matters is that you *materialize the thought*â€”you make it visible. And once itâ€™s visible, you can act on it.

Waypoints are checkpoints for quality and alignment. Each one is a chance to:

* Shape outcomes intentionally
* Halt missteps before they become entrenched
* Capture your standards as reusable artifacts

This is the hidden value of process: not just throughput, but **thought visibility**. Each stage creates space for waypoints, and each waypoint gives you leverage.

Thatâ€™s how structured collaboration worksâ€”not by skipping ahead, but by knowing where to pause, inspect, and shape.

---

## SOPs Are for Workers

Standard operating procedures were always designed for peopleâ€”clear, step-by-step guides to help workers produce consistent, reliable outcomes. Whatâ€™s changed is not the format, but the scope of who counts as a â€œworker.â€

Today, that includes the AI sitting in your chat window.

You donâ€™t need a special AI playbook. The same SOP that guides a new teammate through drafting internal docs can now guide ChatGPT through the same process. Paste it in, give cues, and proceed step by step. The model doesnâ€™t need translation. It needs structureâ€”and SOPs already provide it.

Thatâ€™s the shift: your SOPs now have **runtime**. They donâ€™t just describe what should happen; they **execute** when you walk the model through them.

And the format still works. The best SOPs donâ€™t name the workerâ€”they name the work. They define what needs to be done, why it matters, and what â€œgoodâ€ looks like, without assuming whoâ€”or whatâ€”is doing it.

This isnâ€™t about writing for bots. Itâ€™s about designing systems that any workerâ€”human or virtualâ€”can step into. Thatâ€™s how you scale not just output, but quality. Youâ€™re not building around personalities. Youâ€™re building around **outcomes**.

An AI isnâ€™t a sidekick. Itâ€™s a seat-filler. And with the right SOP, it can sit down and get to work.

---

## ðŸ§­ Running the SOP Manually â€” With a Virtual at the Table

Letâ€™s make this real.

You have a process file called:

> `SOP: Drafting Internal Product Docs`
> (stored at `/Documents/SOPs/drafting-product-docs.md`)

This is your standard operating procedure for creating IT-facing documentationâ€”system overviews, onboarding guides, feature explainers. Itâ€™s used by human teammates across multiple departments.

Hereâ€™s what it includes:

1. Identify the target audience and their common questions
2. Build a topic outline focused on user workflows
3. Draft section content in plain, direct language
4. Apply tone/style guide and format for readability
5. Spot-check accuracy using examples or config snippets

Now, for your latest docâ€”an internal guide to the identity platformâ€”you decide to enlist help from ChatGPT.

Not because the SOP says to.
But because **you know how to pilot a chatbot well**.

---

### ðŸ“¥ Step 1: Delegating Intelligently

You begin the session by pasting in the SOP:

> **Prompt:**
> *Hereâ€™s our SOP for drafting product docs. Youâ€™re to follow it with me as I build documentation for our identity platform. Wait for my cue before each step. Let me know once youâ€™ve read it.*
>
> \[uploads SOP]

ChatGPT replies:

> Understood. The SOP has 5 steps. Ready when you are.

You reply:

> Start with Step 1. The audience is new IT hires onboarding this quarter.

---

### ðŸ› ï¸ Step 1 Output: Identify the Target Audience

> **Audience Summary:**
> â€“ First 90 days on the job
> â€“ Working through onboarding modules
> â€“ High urgency for role-based access clarity
>
> **Common Questions:**
> â€“ What does this platform manage?
> â€“ Why do I have access to things I didnâ€™t request?
> â€“ How do I change my access?
> â€“ Whatâ€™s expected of me re: MFA, password changes, etc.?

You review the output and realize somethingâ€™s missing.

You respond:

> Add: â€œWhat happens if I leave a team or project?â€ Thatâ€™s often overlooked.

ChatGPT updates the list.

âœ… Step 1 completeâ€”*and better than it wouldâ€™ve been alone.*

You move on:

> Letâ€™s do Step 2.

---

### ðŸ› ï¸ Step 2 Output: Topic Outline

> 1. What the Platform Manages
> 2. Who Gets Access and Why
> 3. Role Inheritance and Surprise Access
> 4. Requesting or Changing Access
> 5. Leaving a Team: What Happens
> 6. MFA and Password Management
> 7. Audit Trails and Access History

You notice how that last insightâ€”*Leaving a Team*â€”has now shaped the structure itself. Thatâ€™s what good process enables: judgment captured and turned into structure.

You decide itâ€™s time to update the process.

---

### ðŸ” Updating the SOP Itself

You prompt:

> Insert this line into Step 1:
> â€œPrompt for common confusions around lifecycle events (e.g. team transfers, departures) that affect access.â€

ChatGPT returns the updated markdown. You save it to:

> `/Documents/SOPs/drafting-product-docs.md`

No forked process. No separate â€œAI workflow.â€
Just a smarter SOPâ€”ready for any teammate to follow.

---

## Spec Your Team, Not Just Your Task

Thatâ€™s the shift. Youâ€™re no longer just specifying a task. Youâ€™re **specifying a team**.

Each stage of work can be broken out, defined, and refined independently. You can even review their performance in isolation: â€œHow is my structural editor bot doing? Are they skipping steps?â€ If so, update *that* part of the playbook.

You are building a well-oiled machine. And every part of it runs on the specs you provide.

---

## Bots Can Review Each Other

In the last chapter, we talked about **cloning yourself**â€”building reusable specifications that let the model act more like a trained version of you. But now that weâ€™re working at the process level, itâ€™s time to shift the metaphor.

Youâ€™re no longer just shaping clones of your own judgment.
Youâ€™re **assigning bots to specific roles**â€”modular, goal-oriented workers that slot into your process and carry out defined tasks.

These bots arenâ€™t characters or personalities. Theyâ€™re seat-fillers. Specialists. Helpers trained to do *just this part* of the work, *in this way*, to *this standard*. And that makes them interchangeable, inspectable, andâ€”most importantlyâ€”**reviewable by each other**.

People often talk about AIâ€™s weaknessesâ€”hallucinations, misfires, overconfidence. And those are real. But hereâ€™s the twist: people have those weaknesses too. Thatâ€™s why process exists. It creates **stages**. It defines **roles**. It introduces **checks**. The whole point of a well-structured SOP is to embed those controls into the flow of work.

Whatâ€™s remarkable is that bots donâ€™t just fit into that structureâ€”they *thrive* in it.

The same bot that makes a mistake in one role can be reassigned to anotherâ€”to check facts, to question assumptions, to flag inconsistenciesâ€”and it does. Not because it "feels bad," but because itâ€™s following the system you designed.

> Itâ€™s kind of funny, honestly. The same bot that hallucinated the problem is now the one catching itâ€”because the process told them to.

Imagine this:

* One bot drafts a summary
* A second bot fact-checks it against policy or source material
* A third bot applies tone and formatting rules

Thatâ€™s not magic. Thatâ€™s **structured reuse of intelligence**. Each bot runs a different version of your spec, performing a specific function inside your system.

And if one slips up? Another catches it. Because your waypoints are designed to make the invisible visible.

Even better, the same bot can switch roles midstream. With just a prompt, it changes hats:

> "Now review that summary for unsupported claims. Highlight anything that might require citation."

It can even run a web search to confirm factsâ€”if you ask it to.

Thatâ€™s not just flexibility. Itâ€™s **role awareness**.
And it only works because your process is sound.

The takeaway: these bots arenâ€™t sidekicks. Theyâ€™re workers.
And if your SOPs are clear, they know exactly what seat to fill.

---

## SOPs Are Code

I donâ€™t want you to miss whatâ€™s happening here:

> **SOPs are now programs.**

They are the operational logic we used to hand to people.
Now we hand them to machines.

And the results are shockingly reliableâ€”if the spec is good.

Youâ€™re no longer just writing instructions to align humans.
Youâ€™re writing instructions that *get executed*.

Let that sink in:
**Your SOPs now have runtime.**

---

## The Architecture That Makes It Work

Letâ€™s zoom out.

Everything youâ€™ve seen in this chapterâ€”delegating by step, reviewing intermediate outputs, updating SOPs midstreamâ€”is made possible by a larger architecture. Weâ€™ve touched on this in earlier chapters, but letâ€™s bring it back into view.

At the core, every AI-assisted workflow youâ€™ve run so far is powered by three ingredients:

* **Brain**: the large language model (LLM) doing the reasoning and generation
* **Memory**: the prompt, SOPs, style guides, and uploaded artifacts youâ€™ve provided
* **Tools**: optional add-ons that let the AI take direct actionâ€”searching files, querying systems, triggering automations

In this book, weâ€™ve mostly stayed in the first two zones: brain and memory. Youâ€™ve learned how to prompt deliberately, structure inputs, and create reusable artifacts like SOPs and tone guides. Thatâ€™s been the focusâ€”**working manually but meaningfully**.

Youâ€™ve been riding the bike with training wheels. Not to slow you downâ€”but to give you control.

And itâ€™s working. Youâ€™ve seen that by handing the model a clean spec and walking through the steps yourself, you can produce quality results and even improve your own SOPs in the process. Thatâ€™s not a limitationâ€”itâ€™s a **training ground**.

Now, weâ€™re gesturing toward what comes next. As tools enter the pictureâ€”when the AI can take action on its own, not just respond in chatâ€”the game changes. Suddenly, youâ€™re not just piloting the workflow. Youâ€™re **designing a system** that runs it.

That shift is realâ€”but itâ€™s also premature if you havenâ€™t yet learned the fundamentals.

So for now, this architecture serves one purpose: to help you think holistically.

Know that your artifacts (like SOPs, drafts, and specs) are part of memory. That the LLM is the brain acting on them. And that toolsâ€”when addedâ€”are what let that brain reach into the world and do something.

This is just a mental model. You donâ€™t need to build full automation today. You just need to **understand the terrain**, so that when youâ€™re ready to go further, you already know what levers exist.

---

## ðŸ‘€ What Comes Next: A Glimpse Toward 301

If this chapter feels like a turning point, thatâ€™s because it is.

Youâ€™re no longer just asking ChatGPT to â€œhelp with a task.â€ Youâ€™re designing a repeatable workflow. Youâ€™re managing a system.

And hereâ€™s the best part: youâ€™re still doing it by handâ€”on purpose.

Youâ€™ve learned to delegate step-by-step. To pass files, track decisions, update specs, and reuse artifacts across sessions. Each action you take is a form of **orchestration**: directing a flow of work between roles, rules, and results.

This hands-on, button-by-button approach is not a fallback. Itâ€™s the groundwork for something bigger.

Because once you can run the process manuallyâ€”deliberately, consistentlyâ€”youâ€™re ready to think about automating it. Not as a shortcut, but as a natural evolution.

When tools come into play, youâ€™ll be able to let the AI do more: pull data, update documents, notify stakeholders, even trigger reviews. But that comes later.

First, you build the system.

So if this chapter leaves you with a question, let it be this:

> *What parts of my work could I eventually hand offâ€”not just to an assistant, but to a system that runs the way I would run it?*

Thatâ€™s what weâ€™ll explore in the next tier: **how to orchestrate multiple agents, automate intelligent handoffs, and build workflows that truly scale.**

Youâ€™re closer than you think.
