# Models As Deterministic Snapshots

A model is a snapshot of a mind, literally. It’s frozen. Fixed. Once it’s trained, it doesn’t grow, reflect, or change like a human brain would. It’s not *thinking* in real time — rather it's only able to *apply* what it's already learned.

That frozen quality also means it doesn’t learn anything new after training. Whatever it was taught — books, websites, conversations — was gathered at a specific point in time. After that? No updates, no new facts. It doesn’t know what the day after that is unless someone tells it. That’s why LLMs sometimes give outdated answers. They're stuck in the past.

But ChatGPT isn’t just a model. It’s an app built around one. Its developers compensate by how the app facilitates conversation. When you hit enter, in addition to your latest prompt, it also sends along a bunch of stuff — your full conversation as well as any related search results it finds on the Internet, in that instant.

Think of that payload as a single stream of text, a single unified input, because that's what the model sees. And if you give the model the exact same payload, twice in a row, it tells you the exact same thing, both times. No surprises. No creativity. Just a consistent, repeatable answer. That's what it means to be *deterministic*.
