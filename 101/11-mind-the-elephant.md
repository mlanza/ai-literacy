# Mind The Elephant

You can justify almost anything.

Psychologist Jonathan Haidt says you have an Elephant and a Rider inside your head.

The **Elephant** is your gut — your instincts, emotions, moral reflexes, your “I just feel like it” side.

The **Rider** is your reasoning mind — the part of you that explains, defends, and, frankly, tries to make sense of what the Elephant’s already decided.  The Rider likes to *think* he’s in charge. He makes charts, writes arguments, sets alarms, builds philosophies — but in most moments when the Elephant leans and then veers in a direction, the Rider finds the reason it makes sense to go that way. That is, the mind often justifies what the heart wants.

It’s a feature of being human.  We’re not cold, calculating logic machines. We’re meaning-makers who lead with intuition and then bolt on a clean explanation afterward.

Psychologists call the force that drives this dynamic **cognitive dissonance** — the tension we feel when our beliefs, values, or actions come into conflict. That tension is uncomfortable. And because no one likes living in a state of internal contradiction, the mind works to restore harmony. We rationalize not just to persuade others, but to make peace with ourselves.

On top of that, life isn’t simple. It’s full of nuance, edge cases, and changing contexts. We’re constantly navigating situations where the “right” answer depends on more than just the rule. Black-and-white thinking breaks down fast.

Think about lying.

If I asked you, “Is it okay to lie?” you’d probably say no.

But what if you were hiding someone in your home? When the shooter bursts in demanding their whereabouts, what do you say?

You lie, of course.

Not because you changed your mind about lying, but because the context changed — and with it, your sense of what matters most. The emotional stakes shifted. The logic reassembled itself. And just like that, a once-firm principle made room for a higher priority.

The truth is **almost any belief or action can be justified, given the right values and situation.** What feels like contradiction is often just a shift in context. “It depends” isn’t a cop-out — it’s reflective of reality.

That consequence is often felt when you're talking to AI. Large language models don’t have a fixed stance or a moral compass. They sample language, not truth. So now and then, they’ll generate something that rubs you the wrong way — precisely because they’re channeling a messy, conflicted, nuanced world whose mountains of digital copy have our elephants baked in.
